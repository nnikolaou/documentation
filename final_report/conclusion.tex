Over the course of this internship project, we employed a broad spectrum of data analysis and machine learning techniques to develop fast and high-quality surrogate models for a MC TBR model in use at UKAEA. We generated 900,000 samples for training and test purposes, evaluated on this expensive MC model. We investigated possibilities for simplification of the parameter space, and concluded that no straightforward reduction was possible. After reviewing $N$ surrogate models (fill in $N$), and examining their behaviour on (un)constrained feature space and scaling properties, we retrained some of the best-performing surrogates on the full parameter space. The optimum results obtained were an accuracy of $X$ and a mean prediction time of $X$, representing a relative speedup $X$ with respect to the MC model.

After a thorough review of the literature, we also developed a novel adaptive sampling algorithm, QASS, capable of interfacing with any of the individual studied models. Preliminary testing on a toy theory, qualitatively comparable to the MC TBR model, demonstrated the effectiveness of QASS and behavioural trends consistent with the design of the algorithm. \textit{[Insert numerical results for QASS.]} Further optimisation over the hyperparameter space has strong potential to increase this performance, allowing for future deployment of QASS on the MC TBR model in coalition with any of the most effective identified surrogate models.

\subsection*{Acknowledgements}

TODO: thank supervisory team

\newpage
